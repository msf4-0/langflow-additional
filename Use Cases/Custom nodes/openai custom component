from langflow import CustomComponent
from langflow.field_typing import Data
from langchain.chat_models import ChatOpenAI
from langchain.schema.messages import HumanMessage, SystemMessage
import base64
from typing import Optional
class Component(CustomComponent):
    display_name: str = "Image Interpreter"
    description: str = "Use this component to interpret any image"
    documentation: str = "http://docs.langflow.org/components/custom"
    def encode_image(self,image_path):
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    def build_config(self):
        return {"ChatOpenAI":{"display_name":"Chat Open AI"},
        "Image":{"field_type":"file","suffixes":[".png",".jpeg"],"file_types":["png","jpeg"]},
        "user_request":{"display_name":"user Request","multiline":True,"value":"Describe the image. Focus on Details"},
        "image_url":{"display_name":"Image url"}
        }
    def build(self,ChatOpenAI:ChatOpenAI,Image:Optional[str],user_request:str,image_url:Optional[str]) -> str:
        selected_image_url = ""
        if image_url:
            selected_image_url=image_url
        elif Image:
            base64_image = self.encode_image(Image)
            selected_image_url= f"data:image/png;base64,{base64_image}"
        else:
            raise ValueError("please use one image source")
        response = ChatOpenAI.invoke([HumanMessage(content=[{"type":"text","text":user_request},{"type":"image_url","image_url": selected_image_url}])])
        self.status = response.content
        return response.content
