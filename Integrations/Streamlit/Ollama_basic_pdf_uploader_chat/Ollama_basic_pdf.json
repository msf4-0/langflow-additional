{"name":"Ollama_basic_pdf","description":"Conversational Cartography Unlocked.","data":{"nodes":[{"id":"PromptTemplate-whWRD","type":"genericNode","position":{"x":754.2613768646683,"y":643.8976074744539},"data":{"type":"PromptTemplate","node":{"template":{"output_parser":{"type":"BaseOutputParser","required":false,"placeholder":"","list":false,"show":false,"multiline":false,"fileTypes":[],"password":false,"name":"output_parser","advanced":false,"dynamic":true,"info":"","title_case":true},"input_types":{"type":"dict","required":false,"placeholder":"","list":false,"show":false,"multiline":false,"fileTypes":[],"password":false,"name":"input_types","advanced":false,"dynamic":true,"info":"","title_case":true},"input_variables":{"type":"str","required":true,"placeholder":"","list":true,"show":false,"multiline":false,"fileTypes":[],"password":false,"name":"input_variables","advanced":false,"dynamic":true,"info":"","title_case":true,"value":["question","input"]},"metadata":{"type":"dict","required":false,"placeholder":"","list":false,"show":false,"multiline":false,"fileTypes":[],"password":false,"name":"metadata","advanced":false,"dynamic":true,"info":"","title_case":true},"name":{"type":"str","required":false,"placeholder":"","list":false,"show":false,"multiline":false,"fileTypes":[],"password":false,"name":"name","advanced":false,"dynamic":true,"info":"","title_case":true},"partial_variables":{"type":"dict","required":false,"placeholder":"","list":false,"show":false,"multiline":false,"fileTypes":[],"password":false,"name":"partial_variables","advanced":false,"dynamic":true,"info":"","title_case":true},"tags":{"type":"str","required":false,"placeholder":"","list":true,"show":false,"multiline":false,"fileTypes":[],"password":false,"name":"tags","advanced":false,"dynamic":true,"info":"","title_case":true},"template":{"type":"prompt","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"password":false,"name":"template","advanced":false,"dynamic":true,"info":"","title_case":true,"value":"You are a helpful and polite chat bot that answers user {question} based on this {input}. \n\n\n"},"template_format":{"type":"str","required":false,"placeholder":"","list":false,"show":false,"multiline":false,"value":"f-string","fileTypes":[],"password":false,"name":"template_format","advanced":false,"dynamic":true,"info":"","title_case":true},"validate_template":{"type":"bool","required":false,"placeholder":"","list":false,"show":false,"multiline":false,"value":false,"fileTypes":[],"password":false,"name":"validate_template","advanced":false,"dynamic":true,"info":"","title_case":true},"_type":"PromptTemplate","question":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"question","display_name":"question","advanced":false,"input_types":["Document","BaseOutputParser"],"dynamic":false,"info":"","title_case":true},"input":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"input","display_name":"input","advanced":false,"input_types":["Document","BaseOutputParser"],"dynamic":false,"info":"","title_case":true}},"description":"A prompt template for a language model.","icon":null,"base_classes":["PromptTemplate","BasePromptTemplate","StringPromptTemplate"],"name":"","display_name":"PromptTemplate","documentation":"https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/","custom_fields":{"":["question","input"]},"output_types":[],"full_path":null,"field_formatters":{},"beta":false,"error":null},"id":"PromptTemplate-whWRD","description":"A prompt template for a language model.","display_name":"PromptTemplate"},"selected":false,"width":384,"height":469,"dragging":false,"positionAbsolute":{"x":754.2613768646683,"y":643.8976074744539}},{"id":"PyPDFLoader-uYaI5","type":"genericNode","position":{"x":266.8338653698945,"y":449.009116653044},"data":{"type":"PyPDFLoader","node":{"template":{"file_path":{"type":"file","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"Ant story.pdf","fileTypes":[".pdf"],"file_path":"C:\\Users\\Oyasi\\AppData\\Local\\langflow\\langflow\\Cache\\fa78d8a1-3da5-4c2d-bf49-fcb84a864931\\7fc23716704920457121ecba1caf894694df0539b7dd6ef4a1e0508acb81bd9a.pdf","password":false,"name":"file_path","advanced":false,"dynamic":false,"info":"","title_case":true},"metadata":{"type":"dict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":[{"":""}],"fileTypes":[],"file_path":"","password":false,"name":"metadata","display_name":"Metadata","advanced":false,"dynamic":false,"info":"","title_case":true},"_type":"PyPDFLoader"},"description":"Load PDF using pypdf into list of documents.","base_classes":["Document"],"display_name":"PyPDFLoader","documentation":"https://python.langchain.com/docs/modules/data_connection/document_loaders/how_to/pdf","custom_fields":{},"output_types":["Document"],"field_formatters":{},"beta":false},"id":"PyPDFLoader-uYaI5"},"selected":true,"width":384,"height":367,"dragging":false,"positionAbsolute":{"x":266.8338653698945,"y":449.009116653044}},{"id":"LLMChain-HMbhy","type":"genericNode","position":{"x":1259.9515570797273,"y":417.936004765971},"data":{"type":"LLMChain","node":{"template":{"llm":{"type":"BaseLanguageModel","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"llm","display_name":"LLM","advanced":false,"dynamic":false,"info":"","title_case":true},"memory":{"type":"BaseMemory","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"memory","display_name":"Memory","advanced":false,"dynamic":false,"info":"","title_case":true},"prompt":{"type":"BasePromptTemplate","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"prompt","display_name":"Prompt","advanced":false,"dynamic":false,"info":"","title_case":true},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Callable, Optional, Union\n\nfrom langchain.chains import LLMChain\n\nfrom langflow import CustomComponent\nfrom langflow.field_typing import (\n    BaseLanguageModel,\n    BaseMemory,\n    BasePromptTemplate,\n    Chain,\n)\n\n\nclass LLMChainComponent(CustomComponent):\n    display_name = \"LLMChain\"\n    description = \"Chain to run queries against LLMs\"\n\n    def build_config(self):\n        return {\n            \"prompt\": {\"display_name\": \"Prompt\"},\n            \"llm\": {\"display_name\": \"LLM\"},\n            \"memory\": {\"display_name\": \"Memory\"},\n            \"code\": {\"show\": False},\n        }\n\n    def build(\n        self,\n        prompt: BasePromptTemplate,\n        llm: BaseLanguageModel,\n        memory: Optional[BaseMemory] = None,\n    ) -> Union[Chain, Callable, LLMChain]:\n        return LLMChain(prompt=prompt, llm=llm, memory=memory)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":false,"dynamic":true,"info":"","title_case":true},"_type":"CustomComponent"},"description":"Chain to run queries against LLMs","base_classes":["Chain","Callable","Chain","LLMChain"],"display_name":"LLMChain","documentation":"","custom_fields":{"prompt":null,"llm":null,"memory":null},"output_types":["Chain","Callable","LLMChain"],"field_formatters":{},"beta":true},"id":"LLMChain-HMbhy"},"selected":false,"width":384,"height":425,"positionAbsolute":{"x":1259.9515570797273,"y":417.936004765971},"dragging":false},{"id":"BaseLLM-JIibp","type":"genericNode","position":{"x":722.1833676069085,"y":25.304779574745197},"data":{"type":"BaseLLM","node":{"template":{"base_url":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"base_url","display_name":"Base URL","advanced":false,"dynamic":false,"info":"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.","title_case":true,"value":"http://192.168.0.109:11434"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List, Optional\n\nfrom langchain.llms.base import BaseLLM\nfrom langchain_community.llms.ollama import Ollama\n\nfrom langflow import CustomComponent\n\n\nclass OllamaLLM(CustomComponent):\n    display_name = \"Ollama\"\n    description = \"Local LLM with Ollama.\"\n\n    def build_config(self) -> dict:\n        return {\n            \"base_url\": {\n                \"display_name\": \"Base URL\",\n                \"info\": \"Endpoint of the Ollama API. Defaults to 'http://localhost:11434' if not specified.\",\n            },\n            \"model\": {\n                \"display_name\": \"Model Name\",\n                \"value\": \"llama2\",\n                \"info\": \"Refer to https://ollama.ai/library for more models.\",\n            },\n            \"temperature\": {\n                \"display_name\": \"Temperature\",\n                \"field_type\": \"float\",\n                \"value\": 0.8,\n                \"info\": \"Controls the creativity of model responses.\",\n            },\n            \"mirostat\": {\n                \"display_name\": \"Mirostat\",\n                \"options\": [\"Disabled\", \"Mirostat\", \"Mirostat 2.0\"],\n                \"info\": \"Enable/disable Mirostat sampling for controlling perplexity.\",\n                \"value\": \"Disabled\",\n                \"advanced\": True,\n            },\n            \"mirostat_eta\": {\n                \"display_name\": \"Mirostat Eta\",\n                \"field_type\": \"float\",\n                \"info\": \"Learning rate influencing the algorithm's response to feedback.\",\n                \"advanced\": True,\n            },\n            \"mirostat_tau\": {\n                \"display_name\": \"Mirostat Tau\",\n                \"field_type\": \"float\",\n                \"info\": \"Controls balance between coherence and diversity.\",\n                \"advanced\": True,\n            },\n            \"num_ctx\": {\n                \"display_name\": \"Context Window Size\",\n                \"field_type\": \"int\",\n                \"info\": \"Size of the context window for generating the next token.\",\n                \"advanced\": True,\n            },\n            \"num_gpu\": {\n                \"display_name\": \"Number of GPUs\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of GPUs to use for computation.\",\n                \"advanced\": True,\n            },\n            \"num_thread\": {\n                \"display_name\": \"Number of Threads\",\n                \"field_type\": \"int\",\n                \"info\": \"Number of threads to use during computation.\",\n                \"advanced\": True,\n            },\n            \"repeat_last_n\": {\n                \"display_name\": \"Repeat Last N\",\n                \"field_type\": \"int\",\n                \"info\": \"Sets how far back the model looks to prevent repetition.\",\n                \"advanced\": True,\n            },\n            \"repeat_penalty\": {\n                \"display_name\": \"Repeat Penalty\",\n                \"field_type\": \"float\",\n                \"info\": \"Penalty for repetitions in generated text.\",\n                \"advanced\": True,\n            },\n            \"stop\": {\n                \"display_name\": \"Stop Tokens\",\n                \"info\": \"List of tokens to signal the model to stop generating text.\",\n                \"advanced\": True,\n            },\n            \"tfs_z\": {\n                \"display_name\": \"TFS Z\",\n                \"field_type\": \"float\",\n                \"info\": \"Tail free sampling to reduce impact of less probable tokens.\",\n                \"advanced\": True,\n            },\n            \"top_k\": {\n                \"display_name\": \"Top K\",\n                \"field_type\": \"int\",\n                \"info\": \"Limits token selection to top K for reducing nonsense generation.\",\n                \"advanced\": True,\n            },\n            \"top_p\": {\n                \"display_name\": \"Top P\",\n                \"field_type\": \"int\",\n                \"info\": \"Works with top-k to control diversity of generated text.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(\n        self,\n        base_url: Optional[str],\n        model: str,\n        temperature: Optional[float],\n        mirostat: Optional[str],\n        mirostat_eta: Optional[float] = None,\n        mirostat_tau: Optional[float] = None,\n        num_ctx: Optional[int] = None,\n        num_gpu: Optional[int] = None,\n        num_thread: Optional[int] = None,\n        repeat_last_n: Optional[int] = None,\n        repeat_penalty: Optional[float] = None,\n        stop: Optional[List[str]] = None,\n        tfs_z: Optional[float] = None,\n        top_k: Optional[int] = None,\n        top_p: Optional[int] = None,\n    ) -> BaseLLM:\n        if not base_url:\n            base_url = \"http://localhost:11434\"\n\n        # Mapping mirostat settings to their corresponding values\n        mirostat_options = {\"Mirostat\": 1, \"Mirostat 2.0\": 2}\n\n        # Default to 0 for 'Disabled'\n        mirostat_value = mirostat_options.get(mirostat, 0)  # type: ignore\n\n        # Set mirostat_eta and mirostat_tau to None if mirostat is disabled\n        if mirostat_value == 0:\n            mirostat_eta = None\n            mirostat_tau = None\n\n        try:\n            llm = Ollama(\n                base_url=base_url,\n                model=model,\n                mirostat=mirostat_value,\n                mirostat_eta=mirostat_eta,\n                mirostat_tau=mirostat_tau,\n                num_ctx=num_ctx,\n                num_gpu=num_gpu,\n                num_thread=num_thread,\n                repeat_last_n=repeat_last_n,\n                repeat_penalty=repeat_penalty,\n                temperature=temperature,\n                stop=stop,\n                tfs_z=tfs_z,\n                top_k=top_k,\n                top_p=top_p,\n            )\n\n        except Exception as e:\n            raise ValueError(\"Could not connect to Ollama.\") from e\n\n        return llm\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":false,"dynamic":true,"info":"","title_case":true},"mirostat":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Disabled","fileTypes":[],"file_path":"","password":false,"options":["Disabled","Mirostat","Mirostat 2.0"],"name":"mirostat","display_name":"Mirostat","advanced":true,"dynamic":false,"info":"Enable/disable Mirostat sampling for controlling perplexity.","title_case":true},"mirostat_eta":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"mirostat_eta","display_name":"Mirostat Eta","advanced":true,"dynamic":false,"info":"Learning rate influencing the algorithm's response to feedback.","rangeSpec":{"min":-1,"max":1,"step":0.1},"title_case":true},"mirostat_tau":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"mirostat_tau","display_name":"Mirostat Tau","advanced":true,"dynamic":false,"info":"Controls balance between coherence and diversity.","rangeSpec":{"min":-1,"max":1,"step":0.1},"title_case":true},"model":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":"llava","fileTypes":[],"file_path":"","password":false,"name":"model","display_name":"Model Name","advanced":false,"dynamic":false,"info":"Refer to https://ollama.ai/library for more models.","title_case":true},"num_ctx":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_ctx","display_name":"Context Window Size","advanced":true,"dynamic":false,"info":"Size of the context window for generating the next token.","title_case":true},"num_gpu":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_gpu","display_name":"Number of GPUs","advanced":true,"dynamic":false,"info":"Number of GPUs to use for computation.","title_case":true},"num_thread":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"num_thread","display_name":"Number of Threads","advanced":true,"dynamic":false,"info":"Number of threads to use during computation.","title_case":true},"repeat_last_n":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"repeat_last_n","display_name":"Repeat Last N","advanced":true,"dynamic":false,"info":"Sets how far back the model looks to prevent repetition.","title_case":true},"repeat_penalty":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"repeat_penalty","display_name":"Repeat Penalty","advanced":true,"dynamic":false,"info":"Penalty for repetitions in generated text.","rangeSpec":{"min":-1,"max":1,"step":0.1},"title_case":true},"stop":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"stop","display_name":"Stop Tokens","advanced":true,"dynamic":false,"info":"List of tokens to signal the model to stop generating text.","title_case":true},"temperature":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.8,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"Controls the creativity of model responses.","rangeSpec":{"min":-1,"max":1,"step":0.1},"title_case":true},"tfs_z":{"type":"float","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"tfs_z","display_name":"TFS Z","advanced":true,"dynamic":false,"info":"Tail free sampling to reduce impact of less probable tokens.","rangeSpec":{"min":-1,"max":1,"step":0.1},"title_case":true},"top_k":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"top_k","display_name":"Top K","advanced":true,"dynamic":false,"info":"Limits token selection to top K for reducing nonsense generation.","title_case":true},"top_p":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"top_p","display_name":"Top P","advanced":true,"dynamic":false,"info":"Works with top-k to control diversity of generated text.","title_case":true},"_type":"CustomComponent"},"description":"Local LLM with Ollama.","base_classes":["BaseLLM","BaseLanguageModel"],"display_name":"Ollama","documentation":"","custom_fields":{"base_url":null,"model":null,"temperature":null,"mirostat":null,"mirostat_eta":null,"mirostat_tau":null,"num_ctx":null,"num_gpu":null,"num_thread":null,"repeat_last_n":null,"repeat_penalty":null,"stop":null,"tfs_z":null,"top_k":null,"top_p":null},"output_types":["BaseLLM"],"field_formatters":{},"beta":true},"id":"BaseLLM-JIibp"},"selected":false,"width":384,"height":555,"dragging":false}],"edges":[{"source":"PyPDFLoader-uYaI5","target":"PromptTemplate-whWRD","sourceHandle":"{œbaseClassesœ:[œDocumentœ],œdataTypeœ:œPyPDFLoaderœ,œidœ:œPyPDFLoader-uYaI5œ}","targetHandle":"{œfieldNameœ:œinputœ,œidœ:œPromptTemplate-whWRDœ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}","id":"reactflow__edge-PyPDFLoader-uYaI5{œbaseClassesœ:[œDocumentœ],œdataTypeœ:œPyPDFLoaderœ,œidœ:œPyPDFLoader-uYaI5œ}-PromptTemplate-whWRD{œfieldNameœ:œinputœ,œidœ:œPromptTemplate-whWRDœ,œinputTypesœ:[œDocumentœ,œBaseOutputParserœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input","id":"PromptTemplate-whWRD","inputTypes":["Document","BaseOutputParser"],"type":"str"},"sourceHandle":{"baseClasses":["Document"],"dataType":"PyPDFLoader","id":"PyPDFLoader-uYaI5"}},"style":{"stroke":"#555"},"className":"stroke-gray-900  stroke-connection","animated":false,"selected":false},{"source":"PromptTemplate-whWRD","target":"LLMChain-HMbhy","sourceHandle":"{œbaseClassesœ:[œPromptTemplateœ,œBasePromptTemplateœ,œStringPromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-whWRDœ}","targetHandle":"{œfieldNameœ:œpromptœ,œidœ:œLLMChain-HMbhyœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}","id":"reactflow__edge-PromptTemplate-whWRD{œbaseClassesœ:[œPromptTemplateœ,œBasePromptTemplateœ,œStringPromptTemplateœ],œdataTypeœ:œPromptTemplateœ,œidœ:œPromptTemplate-whWRDœ}-LLMChain-HMbhy{œfieldNameœ:œpromptœ,œidœ:œLLMChain-HMbhyœ,œinputTypesœ:null,œtypeœ:œBasePromptTemplateœ}","data":{"targetHandle":{"fieldName":"prompt","id":"LLMChain-HMbhy","inputTypes":null,"type":"BasePromptTemplate"},"sourceHandle":{"baseClasses":["PromptTemplate","BasePromptTemplate","StringPromptTemplate"],"dataType":"PromptTemplate","id":"PromptTemplate-whWRD"}},"style":{"stroke":"#555"},"className":"stroke-gray-900  stroke-connection","animated":false,"selected":false},{"source":"BaseLLM-JIibp","sourceHandle":"{œbaseClassesœ:[œBaseLLMœ,œBaseLanguageModelœ],œdataTypeœ:œBaseLLMœ,œidœ:œBaseLLM-JIibpœ}","target":"LLMChain-HMbhy","targetHandle":"{œfieldNameœ:œllmœ,œidœ:œLLMChain-HMbhyœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}","data":{"targetHandle":{"fieldName":"llm","id":"LLMChain-HMbhy","inputTypes":null,"type":"BaseLanguageModel"},"sourceHandle":{"baseClasses":["BaseLLM","BaseLanguageModel"],"dataType":"BaseLLM","id":"BaseLLM-JIibp"}},"style":{"stroke":"#555"},"className":"stroke-foreground  stroke-connection","animated":false,"id":"reactflow__edge-BaseLLM-JIibp{œbaseClassesœ:[œBaseLLMœ,œBaseLanguageModelœ],œdataTypeœ:œBaseLLMœ,œidœ:œBaseLLM-JIibpœ}-LLMChain-HMbhy{œfieldNameœ:œllmœ,œidœ:œLLMChain-HMbhyœ,œinputTypesœ:null,œtypeœ:œBaseLanguageModelœ}"}],"viewport":{"x":106.19341629379414,"y":22.658246762782255,"zoom":0.4697613645501199}},"is_component":false,"updated_at":"2024-03-18T07:01:34.270818","folder":null,"id":"fa78d8a1-3da5-4c2d-bf49-fcb84a864931","user_id":"19a586f4-c1e6-46d3-a2d9-ce3213b1df6f"}